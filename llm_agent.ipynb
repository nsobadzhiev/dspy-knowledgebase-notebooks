{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (2.31.0)\n",
      "Requirement already satisfied: chromadb in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (0.4.24)\n",
      "Requirement already satisfied: pypdf in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (4.1.0)\n",
      "Requirement already satisfied: ipywidgets in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (8.1.2)\n",
      "Requirement already satisfied: semantic-text-splitter>==0.7.0 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (0.7.0)\n",
      "Requirement already satisfied: dspy-ai[chromadb] in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (2.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests->-r requirements.txt (line 1)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests->-r requirements.txt (line 1)) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests->-r requirements.txt (line 1)) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests->-r requirements.txt (line 1)) (2024.2.2)\n",
      "Requirement already satisfied: build>=1.0.3 in ./.venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 2)) (1.1.1)\n",
      "Requirement already satisfied: pydantic>=1.9 in ./.venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 2)) (2.5.0)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.3 in ./.venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 2)) (0.7.3)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in ./.venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 2)) (0.110.0)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in ./.venv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 2)) (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.22.5 in ./.venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 2)) (1.26.4)\n",
      "Requirement already satisfied: posthog>=2.4.0 in ./.venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 2)) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./.venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 2)) (4.10.0)\n",
      "Requirement already satisfied: pulsar-client>=3.1.0 in ./.venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 2)) (3.4.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in ./.venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 2)) (1.17.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in ./.venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 2)) (1.23.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in ./.venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 2)) (1.23.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in ./.venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 2)) (0.44b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in ./.venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 2)) (1.23.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in ./.venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 2)) (0.15.2)\n",
      "Requirement already satisfied: pypika>=0.48.9 in ./.venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 2)) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in ./.venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 2)) (4.66.2)\n",
      "Requirement already satisfied: overrides>=7.3.1 in ./.venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 2)) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in ./.venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 2)) (6.3.1)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in ./.venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 2)) (1.62.1)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in ./.venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 2)) (4.1.2)\n",
      "Requirement already satisfied: typer>=0.9.0 in ./.venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 2)) (0.9.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in ./.venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 2)) (29.0.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in ./.venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 2)) (8.2.3)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in ./.venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 2)) (6.0.1)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in ./.venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 2)) (4.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in ./.venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 2)) (3.9.15)\n",
      "Requirement already satisfied: backoff~=2.2.1 in ./.venv/lib/python3.11/site-packages (from dspy-ai[chromadb]->-r requirements.txt (line 4)) (2.2.1)\n",
      "Requirement already satisfied: joblib~=1.3.2 in ./.venv/lib/python3.11/site-packages (from dspy-ai[chromadb]->-r requirements.txt (line 4)) (1.3.2)\n",
      "Requirement already satisfied: openai<2.0.0,>=0.28.1 in ./.venv/lib/python3.11/site-packages (from dspy-ai[chromadb]->-r requirements.txt (line 4)) (1.14.2)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.11/site-packages (from dspy-ai[chromadb]->-r requirements.txt (line 4)) (2.2.1)\n",
      "Requirement already satisfied: regex in ./.venv/lib/python3.11/site-packages (from dspy-ai[chromadb]->-r requirements.txt (line 4)) (2023.12.25)\n",
      "Requirement already satisfied: ujson in ./.venv/lib/python3.11/site-packages (from dspy-ai[chromadb]->-r requirements.txt (line 4)) (5.9.0)\n",
      "Requirement already satisfied: datasets<3.0.0,~=2.14.6 in ./.venv/lib/python3.11/site-packages (from dspy-ai[chromadb]->-r requirements.txt (line 4)) (2.14.7)\n",
      "Requirement already satisfied: optuna in ./.venv/lib/python3.11/site-packages (from dspy-ai[chromadb]->-r requirements.txt (line 4)) (3.6.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.venv/lib/python3.11/site-packages (from pydantic>=1.9->chromadb->-r requirements.txt (line 2)) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.1 in ./.venv/lib/python3.11/site-packages (from pydantic>=1.9->chromadb->-r requirements.txt (line 2)) (2.14.1)\n",
      "Requirement already satisfied: comm>=0.1.3 in ./.venv/lib/python3.11/site-packages (from ipywidgets->-r requirements.txt (line 5)) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in ./.venv/lib/python3.11/site-packages (from ipywidgets->-r requirements.txt (line 5)) (8.22.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in ./.venv/lib/python3.11/site-packages (from ipywidgets->-r requirements.txt (line 5)) (5.14.2)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.10 in ./.venv/lib/python3.11/site-packages (from ipywidgets->-r requirements.txt (line 5)) (4.0.10)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.10 in ./.venv/lib/python3.11/site-packages (from ipywidgets->-r requirements.txt (line 5)) (3.0.10)\n",
      "Requirement already satisfied: packaging>=19.0 in ./.venv/lib/python3.11/site-packages (from build>=1.0.3->chromadb->-r requirements.txt (line 2)) (24.0)\n",
      "Requirement already satisfied: pyproject_hooks in ./.venv/lib/python3.11/site-packages (from build>=1.0.3->chromadb->-r requirements.txt (line 2)) (1.0.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in ./.venv/lib/python3.11/site-packages (from datasets<3.0.0,~=2.14.6->dspy-ai[chromadb]->-r requirements.txt (line 4)) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in ./.venv/lib/python3.11/site-packages (from datasets<3.0.0,~=2.14.6->dspy-ai[chromadb]->-r requirements.txt (line 4)) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in ./.venv/lib/python3.11/site-packages (from datasets<3.0.0,~=2.14.6->dspy-ai[chromadb]->-r requirements.txt (line 4)) (0.3.7)\n",
      "Requirement already satisfied: xxhash in ./.venv/lib/python3.11/site-packages (from datasets<3.0.0,~=2.14.6->dspy-ai[chromadb]->-r requirements.txt (line 4)) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in ./.venv/lib/python3.11/site-packages (from datasets<3.0.0,~=2.14.6->dspy-ai[chromadb]->-r requirements.txt (line 4)) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in ./.venv/lib/python3.11/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets<3.0.0,~=2.14.6->dspy-ai[chromadb]->-r requirements.txt (line 4)) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in ./.venv/lib/python3.11/site-packages (from datasets<3.0.0,~=2.14.6->dspy-ai[chromadb]->-r requirements.txt (line 4)) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in ./.venv/lib/python3.11/site-packages (from datasets<3.0.0,~=2.14.6->dspy-ai[chromadb]->-r requirements.txt (line 4)) (0.21.4)\n",
      "Requirement already satisfied: starlette<0.37.0,>=0.36.3 in ./.venv/lib/python3.11/site-packages (from fastapi>=0.95.2->chromadb->-r requirements.txt (line 2)) (0.36.3)\n",
      "Requirement already satisfied: decorator in ./.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in ./.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in ./.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (2.17.2)\n",
      "Requirement already satisfied: stack-data in ./.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (0.6.3)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (4.9.0)\n",
      "Requirement already satisfied: six>=1.9.0 in ./.venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in ./.venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in ./.venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 2)) (2.28.2)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in ./.venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 2)) (1.7.0)\n",
      "Requirement already satisfied: requests-oauthlib in ./.venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 2)) (1.4.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in ./.venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 2)) (3.2.2)\n",
      "Requirement already satisfied: coloredlogs in ./.venv/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 2)) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in ./.venv/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 2)) (24.3.7)\n",
      "Requirement already satisfied: protobuf in ./.venv/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 2)) (4.25.3)\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 2)) (1.12)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.11/site-packages (from openai<2.0.0,>=0.28.1->dspy-ai[chromadb]->-r requirements.txt (line 4)) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.11/site-packages (from openai<2.0.0,>=0.28.1->dspy-ai[chromadb]->-r requirements.txt (line 4)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.11/site-packages (from openai<2.0.0,>=0.28.1->dspy-ai[chromadb]->-r requirements.txt (line 4)) (0.27.0)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.11/site-packages (from openai<2.0.0,>=0.28.1->dspy-ai[chromadb]->-r requirements.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in ./.venv/lib/python3.11/site-packages (from opentelemetry-api>=1.2.0->chromadb->-r requirements.txt (line 2)) (1.2.14)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=6.0 in ./.venv/lib/python3.11/site-packages (from opentelemetry-api>=1.2.0->chromadb->-r requirements.txt (line 2)) (6.11.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in ./.venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 2)) (1.63.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.23.0 in ./.venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 2)) (1.23.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.23.0 in ./.venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 2)) (1.23.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.44b0 in ./.venv/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 2)) (0.44b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.44b0 in ./.venv/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 2)) (0.44b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.44b0 in ./.venv/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 2)) (0.44b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.44b0 in ./.venv/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 2)) (0.44b0)\n",
      "Requirement already satisfied: setuptools>=16.0 in ./.venv/lib/python3.11/site-packages (from opentelemetry-instrumentation==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 2)) (68.1.2)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in ./.venv/lib/python3.11/site-packages (from opentelemetry-instrumentation==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: asgiref~=3.0 in ./.venv/lib/python3.11/site-packages (from opentelemetry-instrumentation-asgi==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 2)) (3.7.2)\n",
      "Requirement already satisfied: monotonic>=1.5 in ./.venv/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb->-r requirements.txt (line 2)) (1.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in ./.venv/lib/python3.11/site-packages (from typer>=0.9.0->chromadb->-r requirements.txt (line 2)) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in ./.venv/lib/python3.11/site-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 2)) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in ./.venv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 2)) (0.6.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in ./.venv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 2)) (1.0.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in ./.venv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 2)) (0.19.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in ./.venv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 2)) (0.21.0)\n",
      "Requirement already satisfied: websockets>=10.4 in ./.venv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 2)) (12.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in ./.venv/lib/python3.11/site-packages (from optuna->dspy-ai[chromadb]->-r requirements.txt (line 4)) (1.13.1)\n",
      "Requirement already satisfied: colorlog in ./.venv/lib/python3.11/site-packages (from optuna->dspy-ai[chromadb]->-r requirements.txt (line 4)) (6.8.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in ./.venv/lib/python3.11/site-packages (from optuna->dspy-ai[chromadb]->-r requirements.txt (line 4)) (2.0.28)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.11/site-packages (from pandas->dspy-ai[chromadb]->-r requirements.txt (line 4)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.11/site-packages (from pandas->dspy-ai[chromadb]->-r requirements.txt (line 4)) (2024.1)\n",
      "Requirement already satisfied: Mako in ./.venv/lib/python3.11/site-packages (from alembic>=1.5.0->optuna->dspy-ai[chromadb]->-r requirements.txt (line 4)) (1.3.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets<3.0.0,~=2.14.6->dspy-ai[chromadb]->-r requirements.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets<3.0.0,~=2.14.6->dspy-ai[chromadb]->-r requirements.txt (line 4)) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets<3.0.0,~=2.14.6->dspy-ai[chromadb]->-r requirements.txt (line 4)) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets<3.0.0,~=2.14.6->dspy-ai[chromadb]->-r requirements.txt (line 4)) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets<3.0.0,~=2.14.6->dspy-ai[chromadb]->-r requirements.txt (line 4)) (1.9.4)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./.venv/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 2)) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.venv/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 2)) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./.venv/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 2)) (4.9)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=0.28.1->dspy-ai[chromadb]->-r requirements.txt (line 4)) (1.0.4)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets<3.0.0,~=2.14.6->dspy-ai[chromadb]->-r requirements.txt (line 4)) (3.13.1)\n",
      "Requirement already satisfied: zipp>=0.5 in ./.venv/lib/python3.11/site-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb->-r requirements.txt (line 2)) (3.18.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in ./.venv/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./.venv/lib/python3.11/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (0.2.13)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in ./.venv/lib/python3.11/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 2)) (10.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./.venv/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./.venv/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in ./.venv/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (0.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./.venv/lib/python3.11/site-packages (from sympy->onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in ./.venv/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 2)) (0.5.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in ./.venv/lib/python3.11/site-packages (from Mako->alembic>=1.5.0->optuna->dspy-ai[chromadb]->-r requirements.txt (line 4)) (2.1.5)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will setup a locally running LLM and a locally running vector database and embedding function. These will be:\n",
    "* Ollama running Mistral\n",
    "* ChromaDB, running locally, but persistently. The vectors will be stored in the current directory. This can be changed via the `chroma_dir` variable\n",
    "* `DefaultEmbeddingFunction` (part of the ChromaDB lib) will take care of creating embeddings\n",
    "\n",
    "It is assumed that the ChromaDB database is already setup. In order to set it up, you can use the `create_knowledgebase` notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "from dspy.retrieve.chromadb_rm import ChromadbRM\n",
    "from chromadb.utils.embedding_functions import DefaultEmbeddingFunction\n",
    "\n",
    "chroma_dir = './chroma'\n",
    "chroma_collection = 'man_data'\n",
    "\n",
    "chroma_rm = ChromadbRM(\n",
    "    collection_name=chroma_collection,\n",
    "    persist_directory=chroma_dir,\n",
    "    embedding_function=DefaultEmbeddingFunction(),\n",
    "    k=3,\n",
    ")\n",
    "\n",
    "mistral_ollama = dspy.OllamaLocal(\n",
    "    model='mistral',\n",
    "    max_tokens=1000,\n",
    ")\n",
    "dspy.configure(\n",
    "    lm=mistral_ollama,\n",
    "    rm=chroma_rm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' As of my current knowledge up to 2021, the President of Brazil is Jair Bolsonaro. He took office on January 1, 2019. However, please check the most recent and reliable sources for the latest information as political situations can change.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the vanilla LLM\n",
    "mistral_ollama('Who is the president of Brazil?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DocumentFAQ` is a pipeline for retrieving knowledgebase for a question and then using an LLM to answer it.\n",
    "It features a Chain Of Throught step that should improve the performance of the predictiions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentFAQSignature(dspy.Signature):\n",
    "    \"\"\"Answer questions based on the provided context.\"\"\"\n",
    "\n",
    "    context = dspy.InputField(desc=\"facts here are assumed to be true\")\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField()\n",
    "\n",
    "\n",
    "class DocumentFAQ(dspy.Module):\n",
    "    def __init__(self, num_passages=3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.retrieve = dspy.Retrieve(k=3)\n",
    "        self.generate_answer = dspy.ChainOfThought(DocumentFAQSignature)\n",
    "    \n",
    "    def forward(self, question) -> dspy.Prediction:\n",
    "        context = self.retrieve(question).passages\n",
    "        prediction = self.generate_answer(context=context, question=question)\n",
    "        return dspy.Prediction(context=context, answer=prediction.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block is test the pipeline without any training or optimizations. It will just extract three items from the knowledgebase and put them in the context. Then, using Ollama, it will predict the answer and display it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To make a multipart upload using `curl`, you can use the `--form` or `-F` option. Here's an example of how to send a file named `image.jpg` along with some metadata as key-value pairs:\n",
      "\n",
      "```bash\n",
      "# Replace 'https://example.com/upload.php' with your actual upload URL\n",
      "curl --form \"name=JohnDoe\" \\\n",
      "     --form \"email=john.doe@example.com\" \\\n",
      "     --form \"file;file=@image.jpg\" \\\n",
      "     https://example.com/upload.php\n",
      "```\n",
      "\n",
      "In this example, we use the `--\n"
     ]
    }
   ],
   "source": [
    "# Test pipeline\n",
    "\n",
    "question = 'How can I make a multipart upload with curl? Can you write an example for me?'\n",
    "pipeline = DocumentFAQ()\n",
    "prediction = pipeline.forward(question)\n",
    "print(prediction.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding some examples\n",
    "\n",
    "We will add some static examples and feed them as data into the pipeline. There, they can be used as few-shot examples for the prompt. Additionally, they can be used for optimising the parameters of the pipeline.\n",
    "\n",
    "## Examples\n",
    "\n",
    "You will find these examples in the `curl_examples.csv` file. They were generated ahead of time using chatGPT 3.5. They seem to be on par with the format Mistral seems to return as answers, so they should be able to work well together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Example({'num': '2', 'question': 'How do I specify a different name for the downloaded file with `curl`?', 'answer': 'You can use `curl -o [output_file_name] [URL]` to specify a different name for the downloaded file.'}) (input_keys=None),\n",
       " Example({'num': '11', 'question': 'How can I download a file using FTP with `curl`?', 'answer': 'You can specify the FTP protocol by prefixing the URL with `ftp://` and use `curl` as usual.'}) (input_keys=None),\n",
       " Example({'num': '10', 'question': 'How do I send a POST request with `curl`?', 'answer': 'You can use the `-d` option with `curl` to send data as part of a POST request.'}) (input_keys=None)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import dspy\n",
    "\n",
    "from dspy.datasets import Dataset\n",
    "\n",
    "\n",
    "examples_path = './curl_examples.csv'\n",
    "with open(examples_path, 'r') as examples_file:\n",
    "    csv_reader = csv.DictReader(examples_file)\n",
    "    examples: list[dspy.Example] = []\n",
    "    for example_dict in csv_reader:\n",
    "        examples.append(\n",
    "            dspy.Example(\n",
    "                question=example_dict['question'],\n",
    "                answer=example_dict['answer'],\n",
    "            ).with_inputs('question')\n",
    "        )\n",
    "\n",
    "class CSVDataset(Dataset):\n",
    "    def __init__(self, examples_path, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        with open(examples_path, 'r') as examples_file:\n",
    "            csv_reader = csv.DictReader(examples_file)\n",
    "            examples = [example for example in csv_reader]\n",
    "            self._train = examples[:15]\n",
    "            self._dev = examples[15:]\n",
    "\n",
    "dataset = CSVDataset(examples_path)\n",
    "dataset.train[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next pipeline uses a Multi hop step in order to increase the accuracy of preductions for more complex queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsp.utils import deduplicate\n",
    "\n",
    "class GenerateSearchQuery(dspy.Signature):\n",
    "    \"\"\"Write a simple search query that will help answer a complex question.\"\"\"\n",
    "\n",
    "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
    "    question = dspy.InputField()\n",
    "    query = dspy.OutputField()\n",
    "\n",
    "class MultihopFAQ(dspy.Module):\n",
    "    def __init__(self, passages_per_hop=2, max_hops=2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.generate_query = [dspy.ChainOfThought(GenerateSearchQuery) for _ in range(max_hops)]\n",
    "        self.retrieve = dspy.Retrieve(k=passages_per_hop)\n",
    "        self.generate_answer = dspy.ChainOfThought(DocumentFAQSignature)\n",
    "        self.max_hops = max_hops\n",
    "    \n",
    "    def forward(self, question):\n",
    "        context = []\n",
    "        \n",
    "        for hop in range(self.max_hops):\n",
    "            query = self.generate_query[hop](context=context, question=question).query\n",
    "            passages = self.retrieve(query).passages\n",
    "            context = deduplicate(context + passages)\n",
    "\n",
    "        return self.generate_answer(context=context, question=question)\n",
    "        # return dspy.Prediction(context=context, answer=pred.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To prevent the server from serving you cached results and also not sending any cache-related headers, you can use the `--no-cache` option in curl along with other options if needed. Here's an example of how to use it:\n",
      "```bash\n",
      "curl --no-cache [OPTIONS] URL\n",
      "```\n",
      "Replace `[OPTIONS]` with any additional options you might need, such as `--header`, `--data`, or `--compressed`. For instance:\n",
      "```bash\n",
      "curl --no-cache --header \"User-Agent: Mozilla/5.0\" https://example.com/path-to-resource\n",
      "```\n",
      "This command will send\n"
     ]
    }
   ],
   "source": [
    "# Test the multi hop pipeline\n",
    "\n",
    "question = 'How do I set the cache headers in curl so that the server does not give me cached results?'\n",
    "pipeline = MultihopFAQ()\n",
    "prediction = pipeline.forward(question)\n",
    "print(prediction.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM usage for chatcmpl-da39a3ee5e6b4b0d3255bfef95601890afd80709: 156 prompt, 150 completion, 306 total\n",
      "LLM usage for chatcmpl-da39a3ee5e6b4b0d3255bfef95601890afd80709: 992 prompt, 150 completion, 1142 total\n",
      "LLM usage for chatcmpl-da39a3ee5e6b4b0d3255bfef95601890afd80709: 620 prompt, 150 completion, 770 total\n"
     ]
    }
   ],
   "source": [
    "# inspect the LLM usage\n",
    "from summarize_usage import summarize_usages\n",
    "\n",
    "\n",
    "summarize_usages(mistral_ollama.history[-3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding some examples\n",
    "\n",
    "We will add an optimizer to the pipeline. We have 30 examples that we generated manually via chatGPT. Based on the recommendations from GSPy, we should be either using the `BootstrapFewShot` optimizer (that's going to add a few examples to the prompt) and `BootstrapFewShotWithRandomSearch`. The latter is going to use search for the optimal set of examples to add as few-shot examples and add them to the prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to sample between 1 and 3 traces per predictor.\n",
      "Will attempt to train 10 candidate sets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Average Metric: 0.0 / 30  (0.0): 100%|██████████| 30/30 [19:23<00:00, 38.77s/it] \n",
      "/Users/nikola/Projects/opensource/csrf-bypass/.venv/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 30  (0.0%)\n",
      "Score: 0.0 for set: [0, 0, 0]\n",
      "New best score: 0.0 for seed -3\n",
      "Scores so far: [0.0]\n",
      "Best score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 30  (0.0): 100%|██████████| 30/30 [19:37<00:00, 39.26s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 30  (0.0%)\n",
      "Score: 0.0 for set: [3, 3, 3]\n",
      "Scores so far: [0.0, 0.0]\n",
      "Best score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [17:48<00:00, 35.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 0 full traces after 30 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 30  (0.0): 100%|██████████| 30/30 [19:38<00:00, 39.29s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 30  (0.0%)\n",
      "Score: 0.0 for set: [3, 3, 3]\n",
      "Scores so far: [0.0, 0.0, 0.0]\n",
      "Best score: 0.0\n",
      "Average of max per entry across top 1 scores: 0.0\n",
      "Average of max per entry across top 2 scores: 0.0\n",
      "Average of max per entry across top 3 scores: 0.0\n",
      "Average of max per entry across top 5 scores: 0.0\n",
      "Average of max per entry across top 8 scores: 0.0\n",
      "Average of max per entry across top 9999 scores: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [17:48<00:00, 35.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 0 full traces after 30 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 30  (0.0): 100%|██████████| 30/30 [19:50<00:00, 39.68s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 30  (0.0%)\n",
      "Score: 0.0 for set: [3, 3, 3]\n",
      "Scores so far: [0.0, 0.0, 0.0, 0.0]\n",
      "Best score: 0.0\n",
      "Average of max per entry across top 1 scores: 0.0\n",
      "Average of max per entry across top 2 scores: 0.0\n",
      "Average of max per entry across top 3 scores: 0.0\n",
      "Average of max per entry across top 5 scores: 0.0\n",
      "Average of max per entry across top 8 scores: 0.0\n",
      "Average of max per entry across top 9999 scores: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [17:59<00:00, 35.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 0 full traces after 30 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 30  (0.0): 100%|██████████| 30/30 [19:35<00:00, 39.18s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 30  (0.0%)\n",
      "Score: 0.0 for set: [3, 3, 3]\n",
      "Scores so far: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Best score: 0.0\n",
      "Average of max per entry across top 1 scores: 0.0\n",
      "Average of max per entry across top 2 scores: 0.0\n",
      "Average of max per entry across top 3 scores: 0.0\n",
      "Average of max per entry across top 5 scores: 0.0\n",
      "Average of max per entry across top 8 scores: 0.0\n",
      "Average of max per entry across top 9999 scores: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [17:49<00:00, 35.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 0 full traces after 30 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 13  (0.0):  43%|████▎     | 13/30 [12:32<24:25, 86.21s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t HTTPConnectionPool(host='localhost', port=11434): Read timed out. (read timeout=120)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 30  (0.0): 100%|██████████| 30/30 [24:54<00:00, 49.83s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 30  (0.0%)\n",
      "Score: 0.0 for set: [3, 3, 3]\n",
      "Scores so far: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Best score: 0.0\n",
      "Average of max per entry across top 1 scores: 0.0\n",
      "Average of max per entry across top 2 scores: 0.0\n",
      "Average of max per entry across top 3 scores: 0.0\n",
      "Average of max per entry across top 5 scores: 0.0\n",
      "Average of max per entry across top 8 scores: 0.0\n",
      "Average of max per entry across top 9999 scores: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [18:09<00:00, 36.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 0 full traces after 30 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 30  (0.0): 100%|██████████| 30/30 [19:36<00:00, 39.23s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 30  (0.0%)\n",
      "Score: 0.0 for set: [3, 3, 3]\n",
      "Scores so far: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Best score: 0.0\n",
      "Average of max per entry across top 1 scores: 0.0\n",
      "Average of max per entry across top 2 scores: 0.0\n",
      "Average of max per entry across top 3 scores: 0.0\n",
      "Average of max per entry across top 5 scores: 0.0\n",
      "Average of max per entry across top 8 scores: 0.0\n",
      "Average of max per entry across top 9999 scores: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [17:47<00:00, 35.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 0 full traces after 30 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 30  (0.0): 100%|██████████| 30/30 [19:23<00:00, 38.79s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 30  (0.0%)\n",
      "Score: 0.0 for set: [3, 3, 3]\n",
      "Scores so far: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Best score: 0.0\n",
      "Average of max per entry across top 1 scores: 0.0\n",
      "Average of max per entry across top 2 scores: 0.0\n",
      "Average of max per entry across top 3 scores: 0.0\n",
      "Average of max per entry across top 5 scores: 0.0\n",
      "Average of max per entry across top 8 scores: 0.0\n",
      "Average of max per entry across top 9999 scores: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [18:11<00:00, 36.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 0 full traces after 30 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 30  (0.0): 100%|██████████| 30/30 [20:11<00:00, 40.37s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 30  (0.0%)\n",
      "Score: 0.0 for set: [3, 3, 3]\n",
      "Scores so far: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Best score: 0.0\n",
      "Average of max per entry across top 1 scores: 0.0\n",
      "Average of max per entry across top 2 scores: 0.0\n",
      "Average of max per entry across top 3 scores: 0.0\n",
      "Average of max per entry across top 5 scores: 0.0\n",
      "Average of max per entry across top 8 scores: 0.0\n",
      "Average of max per entry across top 9999 scores: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [17:53<00:00, 35.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 0 full traces after 30 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 30  (0.0): 100%|██████████| 30/30 [19:36<00:00, 39.22s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 30  (0.0%)\n",
      "Score: 0.0 for set: [3, 3, 3]\n",
      "Scores so far: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Best score: 0.0\n",
      "Average of max per entry across top 1 scores: 0.0\n",
      "Average of max per entry across top 2 scores: 0.0\n",
      "Average of max per entry across top 3 scores: 0.0\n",
      "Average of max per entry across top 5 scores: 0.0\n",
      "Average of max per entry across top 8 scores: 0.0\n",
      "Average of max per entry across top 9999 scores: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [17:54<00:00, 35.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 0 full traces after 30 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 30  (0.0): 100%|██████████| 30/30 [19:27<00:00, 38.93s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 30  (0.0%)\n",
      "Score: 0.0 for set: [3, 3, 3]\n",
      "Scores so far: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Best score: 0.0\n",
      "Average of max per entry across top 1 scores: 0.0\n",
      "Average of max per entry across top 2 scores: 0.0\n",
      "Average of max per entry across top 3 scores: 0.0\n",
      "Average of max per entry across top 5 scores: 0.0\n",
      "Average of max per entry across top 8 scores: 0.0\n",
      "Average of max per entry across top 9999 scores: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [17:48<00:00, 35.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 0 full traces after 30 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 30  (0.0): 100%|██████████| 30/30 [19:28<00:00, 38.96s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 30  (0.0%)\n",
      "Score: 0.0 for set: [3, 3, 3]\n",
      "Scores so far: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Best score: 0.0\n",
      "Average of max per entry across top 1 scores: 0.0\n",
      "Average of max per entry across top 2 scores: 0.0\n",
      "Average of max per entry across top 3 scores: 0.0\n",
      "Average of max per entry across top 5 scores: 0.0\n",
      "Average of max per entry across top 8 scores: 0.0\n",
      "Average of max per entry across top 9999 scores: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [17:38<00:00, 35.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 0 full traces after 30 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 30  (0.0): 100%|██████████| 30/30 [19:16<00:00, 38.54s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 30  (0.0%)\n",
      "Score: 0.0 for set: [3, 3, 3]\n",
      "Scores so far: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Best score: 0.0\n",
      "Average of max per entry across top 1 scores: 0.0\n",
      "Average of max per entry across top 2 scores: 0.0\n",
      "Average of max per entry across top 3 scores: 0.0\n",
      "Average of max per entry across top 5 scores: 0.0\n",
      "Average of max per entry across top 8 scores: 0.0\n",
      "Average of max per entry across top 9999 scores: 0.0\n",
      "13 candidate programs found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt import BootstrapFewShotWithRandomSearch\n",
    "from metric import metric\n",
    "\n",
    "config = dict(max_bootstrapped_demos=3, max_labeled_demos=3, num_candidate_programs=10, num_threads=4)\n",
    "\n",
    "teleprompter = BootstrapFewShotWithRandomSearch(metric=metric, **config)\n",
    "optimized_program = teleprompter.compile(MultihopFAQ(), trainset=examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the optimised pipeline\n",
    "\n",
    "Runing optimisers can take a long time AND it only needs to be done once (in order to find the optimal parameters). After that, the new, compiled pipeline can just be used (much like the difference between training and inference for traditional ML models).\n",
    "\n",
    "In order to not lose these weights and parameters, we can save the compiled pipeline and later just read it from a file, instead of re-compiling.\n",
    "\n",
    "The training/optimising is something that can be done during the development. And production runs can read a saved compiled pipeline and just run inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_pipeline_path = './compiled/v1.json'\n",
    "optimized_program.save(saved_pipeline_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a saved pipeline\n",
    "\n",
    "Here, the saved parameters are just read from the file and loaded into a DSPy module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate_query[0] = ChainOfThought(StringSignature(context, question -> query\n",
      "    instructions='Write a simple search query that will help answer a complex question.'\n",
      "    context = Field(annotation=str required=True json_schema_extra={'desc': 'may contain relevant facts', '__dspy_field_type': 'input', 'prefix': 'Context:'})\n",
      "    question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
      "    query = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Query:', 'desc': '${query}'})\n",
      "))\n",
      "generate_query[1] = ChainOfThought(StringSignature(context, question -> query\n",
      "    instructions='Write a simple search query that will help answer a complex question.'\n",
      "    context = Field(annotation=str required=True json_schema_extra={'desc': 'may contain relevant facts', '__dspy_field_type': 'input', 'prefix': 'Context:'})\n",
      "    question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
      "    query = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Query:', 'desc': '${query}'})\n",
      "))\n",
      "generate_answer = ChainOfThought(StringSignature(context, question -> answer\n",
      "    instructions='Answer questions based on the provided context.'\n",
      "    context = Field(annotation=str required=True json_schema_extra={'desc': 'facts here are assumed to be true', '__dspy_field_type': 'input', 'prefix': 'Context:'})\n",
      "    question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
      "    answer = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Answer:', 'desc': '${answer}'})\n",
      "))\n"
     ]
    }
   ],
   "source": [
    "loaded_pipeline = MultihopFAQ()\n",
    "loaded_pipeline.load(path=saved_pipeline_path)\n",
    "print(loaded_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    rationale=\"To make curl follow redirects automatically, you can use the `-L` or `--location` option when invoking curl. This tells curl to follow any HTTP location headers it receives and perform a new request using the given URL.\\n\\nHere is an example command:\\n\\n```bash\\ncurl -L https://example.com/some_page\\n```\\n\\nThis command will start by requesting `https://example.com/some_page`. If there's a location header (`Location:`) in the response, curl will follow it and perform another request using the new URL. This process can continue until the final URL does not have any more redirects.\\n\\nUsing this option,\",\n",
       "    answer='To make `curl` follow redirects automatically, use the `-L` or `--location` option when invoking `curl`. For example:\\n\\n```bash\\ncurl -L <URL>\\n```\\n\\nor\\n\\n```bash\\ncurl --location <URL>\\n```\\n\\nThis tells `curl` to follow any HTTP location headers it receives and perform a new request using the given URL. The process can continue until the final URL does not have any more redirects.'\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = loaded_pipeline.forward('How do I tell curl to follow redirects automatically?')\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with the unoptimised models\n",
    "\n",
    "Let's compare the four options we have already:\n",
    "* The vanilla Mistral model that probably already has enough knowledge about curl\n",
    "* The single hop DSPy module we created initially\n",
    "* The multihop module we created in order to give the model the ability to do more reasoning\n",
    "* The optimised multihop module where we let a DSPy optimiser train and find the best parameters\n",
    "\n",
    "We will let all models answer the same questions and compare their results.\n",
    "Wer will also try increasingly more complicated questions to see if the more simplistic models start to fail and the more finetuned ones start to shine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_question = 'How to I specify the HTTP method to use for a curl request?'\n",
    "intermediate_question = 'I need a curl command that does a multipart upload of a file and specifies the media type as image/png. How can I do that?'\n",
    "advanced_question = 'I need a script that uses curl in order to follow an OAuth flow in order to use turn an autorization code into an access token and refresh token. Can you write one for me?'\n",
    "all_questions = [simple_question, intermediate_question, advanced_question]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_prediction(prediction: dspy.Prediction): \n",
    "    print(prediction.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " To specify the HTTP method (such as GET, POST, PUT, DELETE, etc.) for a cURL request, you need to use the `-X` or `--request` option followed by the desired HTTP method. Here's an example using cURL in the command line:\n",
      "\n",
      "```bash\n",
      "curl -X GET <URL> \\\n",
      "  --header \"Authorization: Token <your_token>\" \\\n",
      "  --header 'Content-Type: application/json'\n",
      "```\n",
      "\n",
      "Replace `<URL>` with the target URL, and `<your_token>` with your valid authorization token or other required headers. In this example, we use the GET method.\n",
      "\n",
      "For a POST request, you can set the data to be sent using the `--data` option:\n",
      "\n",
      "```bash\n",
      "curl -X POST <URL> \\\n",
      "  --header \"Content-Type: application/json\" \\\n",
      "  --data '{\"key1\":\"value1\",\"key2\":\"value2\"}'\n",
      "```\n",
      "\n",
      "Replace `<URL>` with the target URL, and set the data as required. In this example, we use the POST method and send JSON data in the request body.\n",
      "\n",
      "For other HTTP methods like PUT or DELETE, you can follow a similar pattern:\n",
      "\n",
      "```bash\n",
      "# For PUT\n",
      "curl -X PUT <URL> \\\n",
      "  --header \"Content-Type: application/json\" \\\n",
      "  --data '{\"key1\":\"value1\",\"key2\":\"value2\"}'\n",
      "\n",
      "# For DELETE\n",
      "curl -X DELETE <URL> \\\n",
      "  --header \"Authorization: Token <your_token>\"\n",
      "```\n",
      "\n",
      "Replace `<URL>` with the target URL and set the data or authorization token as required.\n",
      "--------------\n",
      " To make a multi-part form data upload using `curl` with an image file and specify the media type as `image/png`, you can use the following command:\n",
      "\n",
      "```bash\n",
      "curl --location --request POST \\\n",
      "  'https://your-api-endpoint.com/upload' \\\n",
      "  --header 'Content-Type: multipart/form-data; boundary=----BoundaryString' \\\n",
      "  --data-binary '@path/to/your/image.png; type=application/octet-stream' \\\n",
      "  --data-name 'file' '-- \"Content-Disposition: form-data; name=\\\"media_type\\\"\\r\\nContent-Type: application/x-www-form-urlencoded\\r\\n\\r\\nimage/png\"'\n",
      "```\n",
      "\n",
      "Replace `https://your-api-endpoint.com/upload` with the actual API endpoint URL that accepts multipart form data uploads, and replace `path/to/your/image.png` with the path to your image file on your local system.\n",
      "\n",
      "Make sure you set a unique boundary string (e.g., `----BoundaryString`) for the command. This string is used by `curl` to separate different parts of the multipart form data.\n",
      "\n",
      "This command sends an HTTP POST request with the image file as part of the body, and sets the media type as `image/png` using the `--data-name` option.\n",
      "--------------\n",
      " I'd be happy to help you get started with a bash script using `curl` for an OAuth flow, but please note that this is just a basic example and you may need to adjust it according to your specific use case and the exact API endpoints and parameters provided by the service you are working with.\n",
      "\n",
      "Here's a general outline of what the script should do:\n",
      "\n",
      "1. Obtain an authorization code from the OAuth provider using `curl`.\n",
      "2. Exchange the authorization code for an access token and refresh token using `curl`.\n",
      "3. Store the access token, refresh token, and expiration time securely for future use.\n",
      "\n",
      "Here's a basic script that demonstrates these steps:\n",
      "\n",
      "```bash\n",
      "#!/bin/bash\n",
      "\n",
      "# Set your client ID, client secret, and redirect URI here\n",
      "CLIENT_ID=\"your_client_id\"\n",
      "CLIENT_SECRET=\"your_client_secret\"\n",
      "REDIRECT_URI=\"your_redirect_uri\"\n",
      "\n",
      "# Obtain an authorization code from the OAuth provider using `curl`\n",
      "AUTHORIZATION_CODE=$(curl --silent --location --request GET \\\n",
      "  'https://oauth-provider.com/authorize?response_type=code&client_id=$CLIENT_ID&redirect_uri=$REDIRECT_URI&state=STATE' \\\n",
      "  --header 'Accept: application/json' \\\n",
      "  --data-urlencode 'code=' $(cat authorization_code.txt) | jq -r '.authorization_code')\n",
      "\n",
      "echo \"Authorization code obtained: $AUTHORIZATION_CODE\"\n",
      "\n",
      "# Exchange the authorization code for an access token and refresh token using `curl`\n",
      "ACCESS_TOKEN=$(curl --silent --location --request POST \\\n",
      "  'https://oauth-provider.com/token' \\\n",
      "  --header 'Content-Type: application/x-www-form-urlencoded' \\\n",
      "  --data-urlencode 'grant_type=authorization_code' \\\n",
      "  --data-urlencode 'client_id=$CLIENT_ID' \\\n",
      "  --data-urlencode 'client_secret=$CLIENT_SECRET' \\\n",
      "  --data-urlencode 'redirect_uri=$REDIRECT_URI' \\\n",
      "  --data-urlencode 'code=$AUTHORIZATION_CODE')\n",
      "\n",
      "echo \"Access token obtained: $ACCESS_TOKEN\"\n",
      "\n",
      "# Store the access token, refresh token, and expiration time securely for future use\n",
      "echo \"Access token: $ACCESS_TOKEN\" > access_token.txt\n",
      "echo \"Refresh token: $(echo $ACCESS_TOKEN | jq -r '.refresh_token')\" > refresh_token.txt\n",
      "echo \"Expiration time: $(date --date=$(echo $ACCESS_TOKEN | jq -r '.expires_at'))\" > expiration_time.txt\n",
      "```\n",
      "\n",
      "This script assumes that you have a file named `authorization_code.txt` containing the authorization code obtained from the OAuth provider during the initial authorization request. The access token, refresh token, and expiration time are saved to separate files for security reasons.\n",
      "\n",
      "Please note that this is just a starting point, and you may need to adjust the script according to your specific use case and the exact API endpoints and parameters provided by the OAuth service you are working with. Additionally, make sure to handle any potential errors or edge cases appropriately in your production environment.\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "# Vanilla Ollama\n",
    "for question in all_questions:\n",
    "    response = mistral_ollama(question)\n",
    "    print(response[0])\n",
    "    print('--------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To specify the HTTP method for a curl request, you can use the `-X` or `--request` option followed by the desired HTTP method (such as GET, POST, PUT, DELETE, etc.). Here's an example using the `curl` command with a custom HTTP method called `HEAD_WITH_DATA`:\n",
      "```bash\n",
      "curl --url \"https://example.com\" \\\n",
      "  --X HEAD_WITH_DATA \\\n",
      "  --header 'My-Custom-Header: Value' \\\n",
      "  --data 'Data to send with the HEAD request'\n",
      "```\n",
      "In this example, we are using `curl` command to make a custom HTTP method called `HEAD_WITH_DATA`. This request combines the functionality of both `HEAD` and `POST` methods. The `--X` option is used to specify the custom HTTP method name, while the `--header` and `--data` options are used to send custom headers and data with the request respectively.\n",
      "\n",
      "You can replace `HEAD_WITH_DATA` with any valid HTTP method like `GET`, `POST`, `PUT`, or `DELETE`. For example:\n",
      "```bash\n",
      "curl --url \"https://example.com\" \\\n",
      "  --X POST \\\n",
      "  --header 'My-Custom-Header: Value' \\\n",
      "  --data 'Data to send with the POST request'\n",
      "```\n",
      "In this example, we are using `curl` command to make a custom HTTP method called `POST`. This request combines the functionality of both `GET` and `POST` methods. The `--X` option is used to specify the custom HTTP method name, while the `--header` and `--data` options are used to send custom headers and data with the request respectively.\n",
      "\n",
      "You can use any valid HTTP method like `GET`, `POST`, `PUT`, or `DELETE`. For example:\n",
      "```bash\n",
      "curl --url \"https://example.com\" \\\n",
      "  --X GET \\\n",
      "  --header 'My-Custom-Header: Value'\n",
      "```\n",
      "In this example, we are using the `curl` command to make a simple HTTP method called `GET`. This request only retrieves data from the server without sending any additional data. The `--X` option is used to specify the custom HTTP method name, while the `--header` option is used to send custom headers with the request respectively.\n",
      "--------------\n",
      "To upload a file using curl with the `image/png` media type, you can use the following command:\n",
      "\n",
      "```bash\n",
      "curl --form-string \"name=myfile; filename=path/to/yourfile.png\" \\\n",
      "--form-string \"name=filename; filedescriptor=@path/to/yourfile.png\" \\\n",
      "--header \"Content-Type: multipart/form-data; boundary=----BoundaryString\" \\\n",
      "--request POST \\\n",
      "--data-binary \"@path/to/yourfile.png:filename=@path/to/yourfile.png;type=image/png\" \\\n",
      "https://example.com/upload\n",
      "```\n",
      "\n",
      "Replace `path/to/yourfile.png` with the actual path to your local file, and replace `https://example.com/upload` with the URL of the server-side script that accepts the file upload. Make sure you set the correct boundary string in the `--header` option. This command sends a POST request to the specified URL with a multipart form data containing the file 'yourfile.png', sets its media type as image/png using the Content-Type header, and includes it as part of the multipart form data.\n",
      "--------------\n",
      "To create a GitHub OAuth script using bash and curl, follow these steps:\n",
      "\n",
      "1. Ensure you have the necessary environment variables like `CLIENT_ID`, `CLIENT_SECRET`, and `REDIRECT_URI`.\n",
      "2. Create a new file named `github_oauth.sh` using your preferred text editor or terminal.\n",
      "3. Write the following lines at the beginning of the file:\n",
      "```bash\n",
      "#!/bin/sh\n",
      "CLIENT_ID=\"your_client_id\"\n",
      "CLIENT_SECRET=\"your_client_secret\"\n",
      "REDIRECT_URI=\"https://example.com/auth_callback\"\n",
      "curl --silent --location \\\n",
      "  --header \"Authorization: Bearer $(cat token.txt)\" \\\n",
      "  --data-binary \"<your_twofa_token>\" \\\n",
      "  https://api.github.com/refresh_tokens > tokens.txt\n",
      "```\n",
      "Replace `<your_twofa_token>` with the actual two-factor authentication token you need to provide during the OAuth flow.\n",
      "\n",
      "4. Now, let's write a function that extracts the access token and refresh token from the output file `tokens.txt`. Add the following lines at the end of the file:\n",
      "```bash\n",
      "parse_tokens() {\n",
      "  access_token=$(grep -o 'access_token=\"[^\"]*\"' tokens.txt | sed 's/access_token=//;s/ //g')\n",
      "  refresh_token=$(grep -o 'refresh_token=\"[^\"]*\"' tokens.txt | sed 's/refresh_token=//;s/ //g')\n",
      "  echo \"Access Token: $access_token\"\n",
      "  echo \"Refresh Token: $refresh_token\"\n",
      "}\n",
      "parse_tokens\n",
      "```\n",
      "\n",
      "5. Save and exit the file. Now, you can test your script by running it in your terminal or text editor: `./github_oauth.sh`.\n",
      "6. If everything works correctly, you should see the access token and refresh token printed on the screen.\n",
      "7. You can now use these tokens to make API calls to the GitHub API. Note: This script is just a demonstration of how to extract the access token and refresh token from the output file `tokens.txt`. In real-world scenarios, you might need to store those tokens securely in environment variables or other secure storage solutions.\n",
      "\n",
      "Answer: The provided bash script for GitHub OAuth uses an outdated method for handling two-factor authentication (2FA) tokens. Instead, follow these steps to create a GitHub OAuth script using bash and curl:\n",
      "\n",
      "1. Ensure you have the necessary environment variables like `CLIENT_ID`, `CLIENT_SECRET`, and `REDIRECT_URI`.\n",
      "2. Create a new file named `github_oauth.sh` using your preferred text editor or terminal.\n",
      "3. Write the following lines at the beginning of the file:\n",
      "```bash\n",
      "#!/bin/bash\n",
      "CLIENT_ID=\"your_client_id\"\n",
      "CLIENT_SECRET=\"your_client_secret\"\n",
      "REDIRECT_URI=\"https://example.com/auth_callback\"\n",
      "TOKEN_URL=\"https://github.com/login/oauth/access_token\"\n",
      "REFRESH_TOKEN_URL=\"https://github.com/login/oauth/authorize?client_id=$CLIENT_ID&redirect_uri=$REDIRECT_URI&response_type=code&scope=repo%20user:read_private%20user:read_private\"\n",
      "```\n",
      "\n",
      "4. Add the following function to parse the response from GitHub:\n",
      "```bash\n",
      "parse_response() {\n",
      "  code=$(echo $1 | grep -o 'error_description=\"' | sed 's/error_description=//;s/code=/')\n",
      "  access_token=$(curl -s -b \"https://github.com/login/oauth/access_token?client_id=$CLIENT_ID&code=$code&client_secret=$CLIENT_SECRET\" | jq '.access_token')\n",
      "  refresh_token=$(curl -s -b \"$REFRESH_TOKEN_URL?client_id=$CLIENT_ID&code=$code&scope=repo%20user:read_private%20user:read_private\" --no-store --output text | grep -o 'error_description=\"' | sed 's/error_description=//;s/refresh_token=/' | awk '{print $3}'\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "# DSPy - single hop\n",
    "pipeline = DocumentFAQ()\n",
    "for question in all_questions:\n",
    "    prediction = pipeline.forward(question)\n",
    "    print_prediction(prediction)\n",
    "    print('--------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To specify the HTTP method for a curl request, you can use the `-X` or `--request` option followed by the desired HTTP method. Here are some examples using common HTTP methods:\n",
      "\n",
      "1. GET request:\n",
      "```bash\n",
      "curl https://example.com/\n",
      "```\n",
      "This is the default HTTP method when no method is specified.\n",
      "\n",
      "2. POST request with data:\n",
      "```bash\n",
      "curl -X POST \\\n",
      "  -H \"Content-Type: application/json\" \\\n",
      "  -d '{\"key1\":\"value1\",\"key2\":\"value2\"}' \\\n",
      "  https://example.com/api\n",
      "```\n",
      "3. DELETE request:\n",
      "```bash\n",
      "curl -X DELETE \\\n",
      "  https://example.com/resource\n",
      "```\n",
      "4. PUT request with data:\n",
      "```bash\n",
      "curl -X PUT \\\n",
      "  -H \"Content-Type: application/json\" \\\n",
      "  -d '{\"key1\":\"value1\",\"key2\":\"value2\"}' \\\n",
      "  https://example.com/resource\n",
      "```\n",
      "These examples demonstrate how to use different HTTP methods with curl.\n",
      "--------------\n",
      "To create a `curl` command that does a multipart upload of a file with the specified media type `image/png`, use the following command:\n",
      "\n",
      "```bash\n",
      "curl -X POST \\\n",
      "  -H \"Content-Type: multipart/form-data\" \\\n",
      "  -F \"file=@path/to/yourfile.png:image/png\" \\\n",
      "  https://example.com/upload\n",
      "```\n",
      "\n",
      "Replace `path/to/yourfile.png` with the local path to your image file. This command sends a POST request to the specified URL, uploads the file as a multipart form data, and sets the media type for the file to `image/png`.\n",
      "--------------\n",
      "Here's a Bash script using `curl` for following the OAuth flow with GitHub as an example:\n",
      "\n",
      "```bash\n",
      "#!/bin/bash\n",
      "\n",
      "CLIENT_ID=\"your_client_id\"\n",
      "CLIENT_SECRET=\"your_client_secret\"\n",
      "AUTHORIZATION_CODE=\"authorization_code\"\n",
      "ACCESS_TOKEN=\"\"\n",
      "REFRESH_TOKEN=\"\"\n",
      "\n",
      "function_curl() {\n",
      "  curl \\\n",
      "    -s \\\n",
      "    -X \"$1\" \\\n",
      "    -H \"Authorization: Bearer $2\" \\\n",
      "    \"\" \\\n",
      "    >/dev/null 2>&1 \\\n",
      "    || exit $?\n",
      "}\n",
      "\n",
      "function_get_access_token() {\n",
      "  local access_token_refresh_token;\n",
      "  curl \\\n",
      "    -s \\\n",
      "    -X \"POST\" \\\n",
      "    -H \"Authorization: Bearer $1\" \\\n",
      "    -d \"grant_type=client_confidential\" \\\n",
      "    -d \"code=$2\" \\\n",
      "    https://api.github.com/oauth/token \\\n",
      "    >/dev/null 2>&1 \\\n",
      "    || exit $? > access_token.txt;\n",
      "  access_token=$(cat access_token.txt)\n",
      "  curl \\\n",
      "    -s \\\n",
      "    -X \"POST\" \\\n",
      "    -H \"Authorization: Bearer $1\" \\\n",
      "    -d \"refresh_token=$2\" \\\n",
      "    https://api.github.com/oauth/token \\\n",
      "    >/dev/null 2>&1 \\\n",
      "    || exit $? > refresh_token.txt;\n",
      "  refresh_token=$(cat refresh_token.txt)\n",
      "}\n",
      "\n",
      "ACCESS_TOKEN=\"\"\n",
      "REFRESH_TOKEN=\"\"\n",
      "\n",
      "function_get_access_token \"$CLIENT_SECRET\" \"$AUTHORIZATION_CODE\"\n",
      "\n",
      "echo \"Access Token: $ACCESS_TOKEN\"\n",
      "echo \"Refresh Token: $REFRESH_TOKEN\"\n",
      "```\n",
      "\n",
      "Replace `your_client_id`, `your_client_secret`, and `authorization_code` with your actual values. Make the script executable by running `chmod +x github_oauth.sh`. Run the script with your authorization code: `./github_oauth.sh`. The script will print out your access token and refresh token. You can use these tokens to authenticate API requests to GitHub.\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "# Multihop\n",
    "pipeline = MultihopFAQ()\n",
    "for question in all_questions:\n",
    "    prediction = pipeline.forward(question)\n",
    "    print_prediction(prediction)\n",
    "    print('--------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To specify the HTTP method for a curl request, you can use the `-X` or `--request` option followed by the desired HTTP method. Here are some examples using common HTTP methods:\n",
      "\n",
      "1. GET request:\n",
      "```bash\n",
      "curl https://example.com/\n",
      "```\n",
      "This is the default HTTP method when no method is specified.\n",
      "\n",
      "2. POST request with data:\n",
      "```bash\n",
      "curl -X POST \\\n",
      "  -H \"Content-Type: application/json\" \\\n",
      "  -d '{\"key1\":\"value1\",\"key2\":\"value2\"}' \\\n",
      "  https://example.com/api\n",
      "```\n",
      "3. DELETE request:\n",
      "```bash\n",
      "curl -X DELETE \\\n",
      "  https://example.com/resource\n",
      "```\n",
      "4. PUT request with data:\n",
      "```bash\n",
      "curl -X PUT \\\n",
      "  -H \"Content-Type: application/json\" \\\n",
      "  -d '{\"key1\":\"value1\",\"key2\":\"value2\"}' \\\n",
      "  https://example.com/resource\n",
      "```\n",
      "These examples demonstrate how to use different HTTP methods with curl.\n",
      "--------------\n",
      "To create a `curl` command that does a multipart upload of a file with the specified media type `image/png`, use the following command:\n",
      "\n",
      "```bash\n",
      "curl -X POST \\\n",
      "  -H \"Content-Type: multipart/form-data\" \\\n",
      "  -F \"file=@path/to/yourfile.png:image/png\" \\\n",
      "  https://example.com/upload\n",
      "```\n",
      "\n",
      "Replace `path/to/yourfile.png` with the local path to your image file. This command sends a POST request to the specified URL, uploads the file as a multipart form data, and sets the media type for the file to `image/png`.\n",
      "--------------\n",
      "Here's a Bash script using `curl` for following the OAuth flow with GitHub as an example:\n",
      "\n",
      "```bash\n",
      "#!/bin/bash\n",
      "\n",
      "CLIENT_ID=\"your_client_id\"\n",
      "CLIENT_SECRET=\"your_client_secret\"\n",
      "AUTHORIZATION_CODE=\"authorization_code\"\n",
      "ACCESS_TOKEN=\"\"\n",
      "REFRESH_TOKEN=\"\"\n",
      "\n",
      "function_curl() {\n",
      "  curl \\\n",
      "    -s \\\n",
      "    -X \"$1\" \\\n",
      "    -H \"Authorization: Bearer $2\" \\\n",
      "    \"\" \\\n",
      "    >/dev/null 2>&1 \\\n",
      "    || exit $?\n",
      "}\n",
      "\n",
      "function_get_access_token() {\n",
      "  local access_token_refresh_token;\n",
      "  curl \\\n",
      "    -s \\\n",
      "    -X \"POST\" \\\n",
      "    -H \"Authorization: Bearer $1\" \\\n",
      "    -d \"grant_type=client_confidential\" \\\n",
      "    -d \"code=$2\" \\\n",
      "    https://api.github.com/oauth/token \\\n",
      "    >/dev/null 2>&1 \\\n",
      "    || exit $? > access_token.txt;\n",
      "  access_token=$(cat access_token.txt)\n",
      "  curl \\\n",
      "    -s \\\n",
      "    -X \"POST\" \\\n",
      "    -H \"Authorization: Bearer $1\" \\\n",
      "    -d \"refresh_token=$2\" \\\n",
      "    https://api.github.com/oauth/token \\\n",
      "    >/dev/null 2>&1 \\\n",
      "    || exit $? > refresh_token.txt;\n",
      "  refresh_token=$(cat refresh_token.txt)\n",
      "}\n",
      "\n",
      "ACCESS_TOKEN=\"\"\n",
      "REFRESH_TOKEN=\"\"\n",
      "\n",
      "function_get_access_token \"$CLIENT_SECRET\" \"$AUTHORIZATION_CODE\"\n",
      "\n",
      "echo \"Access Token: $ACCESS_TOKEN\"\n",
      "echo \"Refresh Token: $REFRESH_TOKEN\"\n",
      "```\n",
      "\n",
      "Replace `your_client_id`, `your_client_secret`, and `authorization_code` with your actual values. Make the script executable by running `chmod +x github_oauth.sh`. Run the script with your authorization code: `./github_oauth.sh`. The script will print out your access token and refresh token. You can use these tokens to authenticate API requests to GitHub.\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "# DSPy - optimised and loaded\n",
    "pipeline = loaded_pipeline\n",
    "for question in all_questions:\n",
    "    prediction = pipeline.forward(question)\n",
    "    print_prediction(prediction)\n",
    "    print('--------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test results\n",
    "\n",
    "The results above all show quite good results on all three questions. There are minor differences in the style and contents of the answers, but they have similar contents.\n",
    "\n",
    "One weakness if this test is that curl is a faily popular command and it's very talked about online. This results in faily good results even without providing additional context to the prompt. A more representative comparison between the models should have a knowledgebase domain that is not available to the general public and hence is not somethning the base model is trained on.\n",
    "\n",
    "We also see minor differences in these answers like differences in handling the requirement that hte multipart upload should be specified as PNG in the intermediate question. For the advanced question, some modules provided a more general answer, whereas others gave a concrete example with Github's OAuth scheme. In the latter, the first, single-hop DSPy module (arguably) fell a little short as it gave an answer regarding that particular GitHub scheme, which was not mentioned in the question and might be considered a hallucination. The more advanced, multi-hop module at least mentioned that it was using GitHub purely as an example and that a generic Oauth scheme would be similar.\n",
    "\n",
    "The metric function used didn't seem to provide adequite measurement of the quality of the results (at least not with the currect questions), which resulted in poor optimisation of the pipeline. Evidence to that is the lack of improvement between the unoptimised multi-hop pipeline and the optimised one.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "All DSPy modules showed very good results in answering curl-related questions. There were some nuances and differences in the results, but ultimately all answers were good enough.\n",
    "However, it seems this test was overly simplistic, as it failed to show bad results from any module, even using vanilla Ollama. For more relevant and decisive results, a more complicated and less publically available knowledge domain is needs:\n",
    "* More complicated questions, possibly with multiple instructions to follow\n",
    "* Domain that's doesn't have a lot of public knowledge available on the internet (so base LLMs lack knowledge on it) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
